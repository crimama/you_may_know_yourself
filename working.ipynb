{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from dataset import load_dataset, load_dataloader \n",
    "from models import load_model \n",
    "import yaml \n",
    "import torch \n",
    "import numpy as np \n",
    "import random \n",
    "import os \n",
    "\n",
    "from accelerate import Accelerator\n",
    "import matplotlib.pyplot as plt \n",
    "def img_show(img):    \n",
    "    img = torch.permute(img,dims=(1,2,0)).detach().numpy()\n",
    "    img = (img- np.min(img)) / (np.max(img) - np.min(img))\n",
    "    #img = img[:,:,::-1]\n",
    "    plt.imshow(img)\n",
    "    plt.show()\n",
    "\n",
    "def torch_seed(random_seed):\n",
    "    torch.manual_seed(random_seed)\n",
    "    torch.cuda.manual_seed(random_seed)\n",
    "    torch.cuda.manual_seed_all(random_seed) # if use multi-GPU \n",
    "    # CUDA randomness\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    \n",
    "    np.random.seed(random_seed)\n",
    "    random.seed(random_seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(random_seed)\n",
    "    \n",
    "\n",
    "\n",
    "cfg = yaml.load(open('./configs/default.yaml'),Loader=yaml.Loader)\n",
    "\n",
    "torch_seed(cfg['TRAIN']['seed'])\n",
    "\n",
    "trainset,testset = load_dataset(\n",
    "                                    dataset_name = cfg['DATA']['dataset_name'],\n",
    "                                    dataset_dir  = cfg['DATA']['dataset_dir'],\n",
    "                                    class_name   = cfg['DATA']['class_name'],\n",
    "                                    img_size     = cfg['DATA']['img_size'],\n",
    "                                    batch_size   = cfg['DATA']['batch_size'],\n",
    "                                    **{'mode':'full'}\n",
    "                                )\n",
    "\n",
    "trainloader,validloader,testloader = load_dataloader(trainset,testset,testset,\n",
    "                                                    batch_size = cfg['DATA']['batch_size'],\n",
    "                                                    shuffle=True)\n",
    "\n",
    "model = load_model(\n",
    "                    model_name = cfg['MODEL']['model_name'],\n",
    "                    pretrained = cfg['MODEL']['pretrained'],\n",
    "                    num_class  = len(trainset.l2i),\n",
    "                    )\n",
    "\n",
    "\n",
    "# criterion \n",
    "\n",
    "optimizer = __import__('torch.optim', fromlist='optim').__dict__[cfg['TRAIN']['optimizer']](model.parameters(), lr=cfg['TRAIN']['lr'])\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0=cfg['TRAIN']['epochs'], T_mult=1, eta_min=0.00001)\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "\n",
    "accelerator = Accelerator(mixed_precision = 'fp16')\n",
    "\n",
    "# fit(\n",
    "#     model = model,\n",
    "#     trainloader = trainloader,\n",
    "#     validloader = validloader\n",
    "#     testloader = testloader,\n",
    "#     optimizer = optimizer,\n",
    "#     criterion = criterion,\n",
    "#     config = cfg,\n",
    "#     accelerator = accelerator           \n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "def anomaly_detection_evaluation(testloader,model):\n",
    "    target_ams = [] \n",
    "    pred_ams = [] \n",
    "    target_labels = []\n",
    "    model.eval() \n",
    "    for i, (imgs, gts, labels, anomaly_labels) in enumerate(testloader):\n",
    "        with torch.no_grad():\n",
    "            # Inference \n",
    "            outputs,(x1,x2,x3,x4) = model(imgs)\n",
    "            # Average along channel \n",
    "            x2 = torch.mean(x2,dim=1,keepdim=True)\n",
    "            x4 = torch.mean(x4,dim=1,keepdim=True)\n",
    "            # Interpolatino to target size \n",
    "            x2 = F.interpolate(x2, size=224, mode='bilinear', align_corners=True)\n",
    "            x4 = F.interpolate(x4, size=224, mode='bilinear', align_corners=True)\n",
    "            # Normalize \n",
    "            x2 = torch.concat([(x - torch.min(x)) / (torch.max(x) - torch.min(x)) for x in x2])\n",
    "            x4 = torch.concat([(x - torch.min(x)) / (torch.max(x) - torch.min(x)) for x in x4])\n",
    "            # Calculate Anomaly Score \n",
    "            anomaly_map = torch.pow((x4 - x2),2)\n",
    "            anomaly_map = torch.unsqueeze(anomaly_map,dim=1)\n",
    "            # Anomaly map flatten keeping batch \n",
    "            pred_am = anomaly_map.flatten(1)\n",
    "            target_am = gts.flatten(1).type(torch.int)\n",
    "            \n",
    "            target_ams.append(target_am.detach().cpu().numpy())\n",
    "            pred_ams.append(pred_am.detach().cpu().numpy())\n",
    "            \n",
    "            target_labels.append(anomaly_labels.detach().cpu().numpy())\n",
    "            \n",
    "    target_ams = np.concatenate(target_ams)\n",
    "    pred_ams = np.concatenate(pred_ams)\n",
    "    \n",
    "    target_labels = np.concatenate(target_labels)\n",
    "    pred_labels = np.max(pred_ams,axis=1)\n",
    "    \n",
    "    pixel_auroc = roc_auc_score(target_ams.flatten(),pred_ams.flatten())\n",
    "    img_auroc = roc_auc_score(target_labels.flatten(),pred_labels.flatten())\n",
    "    return img_auroc, pixel_auroc "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "img,pixel = anomaly_detection_evaluation(testloader,model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7046160748302601"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pixel"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
